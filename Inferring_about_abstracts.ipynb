{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87857393-6369-4b66-87c9-5f3253edf28e"
      },
      "source": [
        "#**Inferring**#\n",
        "\n",
        "\n",
        "\n",
        "## *Best Practices In Prompt Engineering*\n",
        "\n",
        "\n",
        "```\n",
        "# Inferring about abstracts\n",
        "```\n"
      ],
      "id": "87857393-6369-4b66-87c9-5f3253edf28e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install packages:"
      ],
      "metadata": {
        "id": "3CIi0Kxdquiu"
      },
      "id": "3CIi0Kxdquiu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYGXfL7X6bS3",
        "outputId": "db002fab-b5e9-45ad-82ae-77be963ddf57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.3/817.3 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install langchain --quiet\n",
        "!pip install openai --quiet\n",
        "!pip install python-dotenv --quiet\n",
        "!pip install pandas --quiet"
      ],
      "id": "cYGXfL7X6bS3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import dependencies:"
      ],
      "metadata": {
        "id": "ADApba-Ir2Ov"
      },
      "id": "ADApba-Ir2Ov"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mRDIhHy6bHa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from getpass import getpass\n",
        "import openai\n",
        "import os"
      ],
      "id": "_mRDIhHy6bHa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set your openAi-key"
      ],
      "metadata": {
        "id": "OiALW6AZsZDW"
      },
      "id": "OiALW6AZsZDW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK6xQZrZlp10",
        "outputId": "6798db1a-4d5b-47e5-9353-74b9f42315d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass()"
      ],
      "id": "EK6xQZrZlp10"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ac673e1"
      },
      "outputs": [],
      "source": [
        "openai.api_key = 'your key'\n",
        "!export OPENAI_API_KEY='your key'\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "openai.api_key  = os.getenv('OPENAI_API_KEY')"
      ],
      "id": "8ac673e1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set gpt-3.5 model"
      ],
      "metadata": {
        "id": "bdG4mRhds_so"
      },
      "id": "bdG4mRhds_so"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKMXejta_G7s"
      },
      "outputs": [],
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]\n",
        "    \n",
        "response = []"
      ],
      "id": "vKMXejta_G7s"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code that reads the file and makes requests to chat-GPT showing the response on the screen."
      ],
      "metadata": {
        "id": "CSXSQHu4tmFp"
      },
      "id": "CSXSQHu4tmFp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTMxJty5_Hpj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Upload the Excel file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the uploaded file name\n",
        "file_name = list(uploaded.keys())[0]\n",
        "print('\\n\\n')\n",
        "\n",
        "# Read the Excel file and extract the 'abstract' and 'title' columns\n",
        "data_frame = pd.read_excel(file_name)\n",
        "abstract_column = data_frame['abstract']\n",
        "title_column = data_frame['title']\n",
        "\n",
        "\n",
        "# Iterate through each item in the 'abstract' column and display its content\n",
        "for item in abstract_column:\n",
        "    prompt = f\"\"\"\n",
        "    Determine whether the five issues outlined below are being discussed at \\\n",
        "    following text, which is delimited by triple backticks.\n",
        "\n",
        "    ''' \"Evolutionary approaches\", \"dynamic planning\", \"autonomous navigation\", \"unknown environment\", \"flying or aquatic robots\"\n",
        "\n",
        "\n",
        "    Format your response as a line-break-separated list of items following the template:\n",
        "\n",
        "    Evolutionary approaches - Positive\n",
        "    Dynamic planning - Negative\n",
        "\n",
        "    Example text: '''{item}'''\n",
        "    \"\"\"\n",
        "    response.append(get_completion(prompt))\n",
        "\n",
        "for r in response:\n",
        "    index = response.index(r)\n",
        "    print(title_column[index])\n",
        "    print(r + \"\\n\")\n",
        "    "
      ],
      "id": "qTMxJty5_Hpj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Output:\n",
        "\n",
        "Learning and adaptation of an intelligent mobile robot navigator operating in unstructured environment based on a novel online Fuzzy-Genetic system\n",
        "Evolutionary approaches - Positive\n",
        "Dynamic planning - Positive\n",
        "Autonomous navigation - Positive\n",
        "Unknown environment - Positive\n",
        "Flying Robots - Positive\n",
        "\n",
        "Efficient path planning algorithm for mobile robot navigation with a local minima problem solving\n",
        "Evolutionary approaches - Negative\n",
        "Dynamic planning - Positive\n",
        "Autonomous navigation - Positive\n",
        "Unknown environment - Positive\n",
        "Flying Robots - Positive\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "B2_Jy0UyvYoP"
      },
      "id": "B2_Jy0UyvYoP"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}